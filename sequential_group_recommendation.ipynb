{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Assumptions:\n",
        "1. User have similar rating in past will have similar rating in future.\n",
        "2. For computing pearson similarity we consider only the rating which user 1 and user 2 both has value. If either of it is not available like \"Nan\" value that rating is not considered.\n",
        "3. The preference of user stays consistent over time.\n",
        "4. The movie rating for a target user is almost Nan which means only 5-10% we have values. So the missing ratings is first computed.\n",
        "5. For predicting movie recommendations for a user we need to first predict the missing movie ratings of the user in target with the similar users (top 100 similar users is considered) first and then the ratings are sorted and top K is picked up and displayed to the user as top K recommended movies for user in target.\n",
        "6. When a top similiar users doesnt have the movie rating which is considered for prediction then the target users movie rating's mean is returned and stored as the rating for that movie.\n",
        "7. For predicting single user top k movies, 100 similar users were considered and top 200 movies are suggested for each user.\n",
        "8. Each user in a considered group has top 200 movies recommended for them seperately and commonly rated movies by all 3 users in the group is retrieved.\n",
        "9. These commonly rated movies are then sent to aggregation function such as weighted average and least misery for obtaining combined group recommendation for this specific group using hybrid aggregation.\n",
        "10. Dataset is divided into j chunks depending on number of iteration sequence(j) required.\n",
        "11. For suggesting the first set of recommendation we use the data chunk 1 and compute movie rating for the users in group and generate aggregated lists and we set alpha = 0 so that the hybrid aggregation function returns top 10 movies for round 1 completely from the weighted average aggregation list.\n",
        "12. For computing the user satisfaction for each user from their top 200 recommended movies the first top K(eg: 10) movies is considered and the ratings for this movies alone are summed and used as the denominator. And for the numerator the group recommended movies which are present in top k list of that target user is taken but to sum up the movie ratings of the filtered common movies we will use the rating value available from the target users list.\n",
        "13. For computing the disagreement \"Coefficient of variation\" method is used this is conputed for each j iteration.\n",
        "14. For recommending the 2nd round of top k movie list this disagreement is considered. Utilising the 2nd chunk of dataset for predicting unknown movie ratings of the users in group and using aggregations proposed the aggregated list is formed and top k movies are displayed to the group and agin satisfaction and disagreement score is computed. It is repeated for next j iterations and top K recommended movies list are given to the group at the end of each iteration sequence.\n"
      ],
      "metadata": {
        "id": "5eSaRE2KS8U4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running Instruction:\n",
        "1. u.data, u.item, u.user <- these are the 3 files needed for running this code.\n",
        "2. Preferrably run the file in colab and have these 3 data files in drive.\n",
        "3. Cells are in order so it can be run from top to bottom one by one.\n",
        "4. For selecting users to form a group rather than the test input which is already given, there is a separate K means clustering function from which the users can be picked manually from a single cluster.\n",
        "5. The **Testing** happens on the **2nd last code cell** of this notebook which has the comment line called \"#testing\" there we can vary the sequenceIteration required (j) and topMovies (K) which are currently set as 3 and 10 respectively depending on the assignment requirement.The group size is fixed so it should be 3 users all the time. If we want to test this for different set of users we can do that by editing the users=[] array and give the user id's inside this array\n",
        "\n"
      ],
      "metadata": {
        "id": "mZKfQ2KmjIRa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tQyvRziCFczn"
      },
      "outputs": [],
      "source": [
        "#importing necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from collections import defaultdict\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import pairwise_distances_argmin_min"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "drive.mount('/content/drive')\n",
        "file_path_u_data = '/content/drive/My Drive/RS/u.data'\n",
        "file_path_u_user = '/content/drive/My Drive/RS/u.user'\n",
        "file_path_u_item = '/content/drive/My Drive/RS/u.item'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UX16NGTJjbNm",
        "outputId": "da2c4532-e64c-4c63-d2e1-04c1656f5a0a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " **part 1  -  Importing data**"
      ],
      "metadata": {
        "id": "v8hP1FfBSOEx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Hi1U5dxeFfaZ"
      },
      "outputs": [],
      "source": [
        "#updating respective variables with the data imported\n",
        "column_names=[\"user_id\", \"item_id\",  \"rating\", \"timestamp\"]\n",
        "df=pd.read_table(file_path_u_data,header=None,names=column_names)\n",
        "df = df.drop(\"timestamp\", axis=1)\n",
        "user_item_matrix = df.pivot(index=\"user_id\", columns=\"item_id\", values=\"rating\")\n",
        "\n",
        "col_names = {\n",
        "    \"item\": ['movie id' , 'movie title' , 'release date' , 'video release date' ,\n",
        "              'IMDb URL' , 'unknown' , 'Action' , 'Adventure' , 'Animation' ,\n",
        "              \"Children's\" , 'Comedy' , 'Crime' , 'Documentary' , 'Drama' , 'Fantasy' ,\n",
        "              'Film-Noir' , 'Horror' , 'Musical' , 'Mystery' , 'Romance' , 'Sci-Fi' ,\n",
        "              'Thriller' , 'War' , 'Western'],\n",
        "    \"user\": ['user id' , 'age' , 'gender' , 'occupation' , 'zip code']\n",
        "}\n",
        "movies = pd.read_table(file_path_u_item, header = None, sep='|', names = col_names[\"item\"],  encoding='latin-1')\n",
        "users = pd.read_table(file_path_u_user, header = None, sep='|', names = col_names[\"user\"],  encoding='utf-8')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#finding similar users and forming groups\n",
        "\n",
        "#since Knn doesnt accept Nan it is being replced with 0\n",
        "user_item_matrix_without_nan = np.nan_to_num(user_item_matrix, nan=0)\n",
        "\n",
        "# Number of clusters (groups) to create\n",
        "num_clusters = 10\n",
        "\n",
        "# Perform k-means clustering on the user-item matrix\n",
        "kmeans = KMeans(n_clusters=num_clusters, random_state=30)\n",
        "\n",
        "cluster_assignments = kmeans.fit_predict(user_item_matrix_without_nan)\n",
        "\n",
        "# Identify the representative user for each cluster\n",
        "representative_users = pairwise_distances_argmin_min(kmeans.cluster_centers_, user_item_matrix_without_nan)\n",
        "\n",
        "# Print the clusters and representative users\n",
        "for i in range(num_clusters):\n",
        "    cluster_users = np.where(cluster_assignments == i)[0]\n",
        "    print(f\"\\nCluster {i + 1} Users: {cluster_users}\")\n",
        "    print(f\"Representative User for Cluster {i + 1}: {representative_users[0][i]}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0Dtv6b2wNOh",
        "outputId": "4f674ea2-c122-4f78-ef42-97d6b5e50461"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cluster 1 Users: [  2   3  28  32  33  34  35  38  39  45  46  60  73  85  87  99 104 106\n",
            " 110 111 112 115 125 126 128 132 133 139 142 145 146 148 154 165 169 170\n",
            " 172 178 190 203 204 205 219 228 239 240 257 259 260 272 277 280 281 283\n",
            " 301 303 308 316 318 334 340 350 352 354 355 361 363 376 383 387 399 403\n",
            " 407 409 413 417 422 426 427 430 439 442 443 445 447 450 460 461 463 481\n",
            " 484 488 501 506 508 509 510 514 518 519 528 530 543 546 549 556 563 569\n",
            " 573 577 586 588 595 597 610 615 625 627 630 634 645 651 655 667 672 674\n",
            " 675 680 682 686 687 694 695 700 701 712 719 723 724 728 731 739 742 749\n",
            " 751 754 771 774 781 782 783 786 790 800 801 802 807 808 809 810 811 812\n",
            " 815 817 818 819 823 826 827 831 840 841 844 852 855 859 862 865 870 872\n",
            " 897 904 914 919 925 930]\n",
            "Representative User for Cluster 1: 925\n",
            "\n",
            "Cluster 2 Users: [  7  21  36 101 109 118 144 157 177 196 216 220 248 255 266 319 327 331\n",
            " 345 346 373 424 441 446 452 465 486 492 520 585 599 618 620 626 637 639\n",
            " 670 704 708 714 745 756 773 787 825 850 932 942]\n",
            "Representative User for Cluster 2: 745\n",
            "\n",
            "Cluster 3 Users: [ 10  11  13  23  24  27  40  47  48  57  64  71  72  75  76  81  90  95\n",
            "  96 113 114 117 137 143 147 151 153 159 173 176 186 187 206 212 213 214\n",
            " 215 231 232 234 235 236 249 252 261 262 263 269 271 274 287 291 295 296\n",
            " 297 314 315 317 321 324 337 341 343 349 359 360 369 370 379 380 382 390\n",
            " 391 396 400 410 411 420 425 435 455 457 464 467 477 479 480 487 495 497\n",
            " 498 499 507 522 526 537 541 542 552 553 558 561 565 578 590 600 604 607\n",
            " 609 614 624 628 638 644 657 660 664 668 678 685 689 692 697 703 709 720\n",
            " 730 733 740 747 752 755 762 772 775 779 805 820 834 837 843 846 849 853\n",
            " 866 874 877 884 889 902 907 910 911 912 917 923 928 939 941]\n",
            "Representative User for Cluster 3: 699\n",
            "\n",
            "Cluster 4 Users: [ 91  93 129 221 275 290 302 416 434 456 471 550 681 863 879]\n",
            "Representative User for Cluster 4: 221\n",
            "\n",
            "Cluster 5 Users: [ 42 344 377 392 415 449 795]\n",
            "Representative User for Cluster 5: 377\n",
            "\n",
            "Cluster 6 Users: [  5   6   9  17  59  84  89 150 183 188 193 233 238 268 270 298 304 311\n",
            " 312 320 333 338 353 378 384 388 405 408 436 451 473 502 523 534 536 560\n",
            " 566 658 663 665 693 706 715 746 839 845 847 882 931]\n",
            "Representative User for Cluster 6: 320\n",
            "\n",
            "Cluster 7 Users: [  0  12  58 200 292 307 326 342 362 386 428 591 654 757 822 832 869 885\n",
            " 888 895 915]\n",
            "Representative User for Cluster 7: 932\n",
            "\n",
            "Cluster 8 Users: [  1  14  20  25  31  44  51  53  56  62  65  68  74  80  83  88  98 100\n",
            " 103 116 136 140 156 158 163 167 175 180 185 189 192 202 222 250 264 273\n",
            " 276 286 293 322 323 335 347 356 395 401 402 421 431 433 437 458 462 469\n",
            " 485 500 517 524 525 533 539 547 551 559 568 579 581 594 598 619 623 629\n",
            " 633 636 643 662 673 676 688 696 698 702 707 713 716 717 721 729 732 758\n",
            " 760 763 767 769 778 791 792 824 830 833 838 871 878 890 892 893 906 909\n",
            " 918 920 922 934 935 937 938]\n",
            "Representative User for Cluster 8: 677\n",
            "\n",
            "Cluster 9 Users: [  8  16  18  19  26  29  30  49  50  52  54  66  67  70  77  78  79  92\n",
            "  97 102 105 107 119 120 121 122 123 130 131 134 135 138 141 149 152 155\n",
            " 160 161 162 164 166 168 171 174 179 181 182 184 191 194 195 198 201 207\n",
            " 208 210 211 217 218 223 224 225 226 227 230 237 241 242 244 246 247 251\n",
            " 254 256 258 265 282 284 288 299 305 309 328 330 332 336 339 348 351 357\n",
            " 358 364 365 366 367 368 371 374 375 381 385 389 394 412 414 418 419 423\n",
            " 429 432 438 440 444 448 459 466 468 470 472 474 475 476 482 489 490 491\n",
            " 493 511 512 515 516 521 527 529 538 545 548 554 555 557 562 564 567 570\n",
            " 571 572 574 575 580 582 583 584 589 593 596 601 602 603 606 608 611 612\n",
            " 613 616 622 632 635 640 646 648 650 656 661 666 669 671 677 679 683 684\n",
            " 690 691 699 705 718 722 725 727 734 735 736 738 741 743 744 753 759 761\n",
            " 764 766 768 770 776 777 780 784 788 793 796 798 799 813 816 821 828 835\n",
            " 836 848 851 854 856 857 858 860 864 868 873 875 876 883 887 894 899 901\n",
            " 903 905 908 913 916 924 927 929 936 940]\n",
            "Representative User for Cluster 9: 684\n",
            "\n",
            "Cluster 10 Users: [  4  15  22  37  41  43  55  61  63  69  82  86  94 108 124 127 197 199\n",
            " 209 229 243 245 253 267 278 279 285 289 294 300 306 310 313 325 329 372\n",
            " 393 397 398 404 406 453 454 478 483 494 496 503 504 505 513 531 532 535\n",
            " 540 544 576 587 592 605 617 621 631 641 642 647 649 652 653 659 710 711\n",
            " 726 737 748 750 765 785 789 794 797 803 804 806 814 829 842 861 867 880\n",
            " 881 886 891 896 898 900 921 926 933]\n",
            "Representative User for Cluster 10: 274\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pearson similarity Function"
      ],
      "metadata": {
        "id": "yN9mUMr9wShn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#PEARSON SIMILARITY FUNCTION MANUAL IMPLEMENTATION\n",
        "\n",
        "def pearson_correlation_computed_function(target_user, user2, user_item_matrix):\n",
        "    # Find common items rated by both users\n",
        "    common_items = (user_item_matrix.loc[target_user].dropna().index).intersection(user_item_matrix.loc[user2].dropna().index)\n",
        "    if len(common_items) == 0:\n",
        "        return 0  # No common items, so correlation is 0\n",
        "\n",
        "    # Extract the ratings for the common items\n",
        "    #r(a,p)\n",
        "    user1_ratings = [user_item_matrix.loc[target_user][i] for i in common_items]\n",
        "    #r(b,p)\n",
        "    user2_ratings = [user_item_matrix.loc[user2][i] for i in common_items]\n",
        "\n",
        "    # Calculate the mean ratings for both users\n",
        "    # mean(r_a)\n",
        "    mean_user1 = np.mean(user1_ratings)\n",
        "    #  mean(r_b)\n",
        "    mean_user2 = np.mean(user2_ratings)\n",
        "\n",
        "    # Calculate the numerator and denominators for Pearson correlation\n",
        "    # (Σp[(r(a,p) - mean(r_a)) * (r(b,p) - mean(r_b)]) for every p belongs to set \"P\" - which has common ratings from target user as well as user in consideration.\n",
        "    numerator = sum((user1_ratings[i] - mean_user1) * (user2_ratings[i] - mean_user2) for i in range(len(common_items)))\n",
        "    #  [√(Σ(r(a,p) - mean(r_a)² * √(Σ(r(b,p) - mean(r_b)²)]\n",
        "    denominator_user1 = np.sqrt(sum((user1_ratings[i] - mean_user1) ** 2 for i in range(len(common_items))))\n",
        "    denominator_user2 = np.sqrt(sum((user2_ratings[i] - mean_user2) ** 2 for i in range(len(common_items))))\n",
        "\n",
        "    # Calculate the Pearson correlation coefficient\n",
        "    if denominator_user1 == 0 or denominator_user2 == 0:\n",
        "        return 0  # Handle division by zero\n",
        "    else:\n",
        "       #pearson correlation = (Σp[(r(a,p) - mean(r_a)) * (r(b,p) - mean(r_b)])/ [√(Σ(r(a,p) - mean(r_a)² * √(Σ(r(b,p) - mean(r_b)²)]\n",
        "        correlation = numerator / (denominator_user1 * denominator_user2)\n",
        "        return correlation\n",
        "\n",
        "#pearson_similarity = pearson_correlation(user1, user2)\n",
        "#print(f\"Pearson Correlation: {pearson_similarity}\")\n",
        "\n",
        "\n",
        "#calls manually defined pearson function iteratively to compute similarity for all the user 942 users exlusing the target user.\n",
        "#parameter explanation - (target_user) -> user for whom the recommendation is required, (num_users) -> consider num_users as a int n it is like returning top n closely similar user to the user in target.\n",
        "def find_similar_users_with_compute_pearson(target_user, num_users,user_item_matrix):\n",
        "    similarities = {}\n",
        "    #iterating over each user in the user-item matrix\n",
        "    for user in user_item_matrix.index:\n",
        "        #condition to skip when the current user in the iteration is equal to the target user. Since we dont want to compute pearson similarity for a target user user the target user himself.\n",
        "        if user != target_user:\n",
        "            #computing similarity for target user eg:Alice with other user eg:user1(increased like user2, user3 till users 943 one by one) using predefined pearson function\n",
        "            #similarity = pearson_correlation_predefined(target_user, user)\n",
        "            #computing similarity for target user eg:Alice with other user eg:user1(increased like user2, user3 till users 943 one by one) using formula based computed pearson function\n",
        "            similarity = pearson_correlation_computed_function(target_user, user, user_item_matrix)\n",
        "            #similarities are stored in this array called \"similarities\" with respect to each user_id as as its index. Eg: similarity[102] gives the similarity value between the target user and the user 102.\n",
        "            similarities[user] = similarity\n",
        "    #filtered_similarity = {k: v for k, v in similarities.items() if not isinstance(v, float) or not math.isnan(v)}\n",
        "    return sorted(similarities.items(), key=lambda x: x[1], reverse=True)[:num_users]\n",
        "\n",
        "#PREDICTION FUNCTION GIVEN IN CLASS\n",
        "\n",
        "\n",
        "def prediction_funciton_inclass(targetUser,movie,pearsonResult100,meanRA,user_item_matrix):\n",
        "    #defining how many neighbors should be considered for predicting movie rating\n",
        "    #num_users=100\n",
        "    #pearsonResult=find_similar_users_with_compute_pearson(targetUser, num_users)\n",
        "\n",
        "    #similar users and their corresponding similarity values for top 100 users are computed and stored.\n",
        "    #finding out of these similar users which users has the rated value for movie which the prediction should be done to the target user. Eg: if movie number 101 for the target user needs to be prediction even from the top 100 similar user to the target user is considered entirely. We should implement a filter which filters only the user which has rating for this secific movie.\n",
        "    similarUsers=[item[0] for item in pearsonResult100]\n",
        "    similarUserWithRating=[]\n",
        "    for i in similarUsers:\n",
        "      if(not math.isnan(user_item_matrix.loc[i][movie])):\n",
        "        #print(user_item_matrix.loc[i][movie])\n",
        "        similarUserWithRating.append(i)\n",
        "    filteredPearsonResult=[]\n",
        "    for item in pearsonResult100:\n",
        "      if item[0] in similarUserWithRating:\n",
        "        filteredPearsonResult.append(item)\n",
        "\n",
        "    filteredPearsonResultArr = np.array(filteredPearsonResult)\n",
        "    #if there is ratings for that particular movie with top 100 users then compute the below else return mean of RA\n",
        "    if filteredPearsonResultArr.size != 0:\n",
        "        #compute rest of the formula\n",
        "        numer=0\n",
        "        denom=0\n",
        "        #print(filteredPearsonResult)\n",
        "        #print(\"predicting movie...\",movie)\n",
        "        for simUser,simAB in filteredPearsonResult:\n",
        "          common_items = (user_item_matrix.loc[targetUser].dropna().index).intersection(user_item_matrix.loc[simUser].dropna().index)\n",
        "          if len(common_items) == 0:\n",
        "              return 0  # No common items, so correlation is 0\n",
        "\n",
        "          # Extract the ratings for the common items\n",
        "          #r(b,p)\n",
        "          rb_ratings = [user_item_matrix.loc[simUser][i] for i in common_items]\n",
        "\n",
        "          #r_a(mean target user rating)\n",
        "          ra_ratings = [user_item_matrix.loc[simUser][i] for i in common_items]\n",
        "\n",
        "          # Calculate the mean ratings for both user\n",
        "          #  mean(r_b)\n",
        "          meanRB = np.mean(rb_ratings)\n",
        "\n",
        "          #curret users movie rating for the speific movie in prediction\n",
        "          Rbp=user_item_matrix.loc[simUser][movie]\n",
        "\n",
        "          #computes the numerator part of the given predictor function (sum(sim(a,b)*(rbp-mean(r_b)))\n",
        "          cal=(simAB*(Rbp-meanRB))\n",
        "          numer+=cal\n",
        "          #computes the denominator part of the given predictor function (sum(sim(a,b)))\n",
        "          denom+=simAB\n",
        "\n",
        "        #final computation of the predictor function\n",
        "        #pred(a,p)=mean(r_a)+(sum(sim(a,b)*(rbp-mean(r_b)))/(sum(sim(a,b)))\n",
        "        return meanRA+(numer/denom)\n",
        "    else:\n",
        "      return meanRA\n",
        "\n",
        "\n",
        "#finding similar movies\n",
        "def predict_topmovies_forSingleUser(selectedUser,topMovies,similarUser,user_item_matrix):\n",
        "    print(\"predicting for user\",selectedUser)\n",
        "    user_ratings = user_item_matrix.loc[selectedUser]\n",
        "    new_movie_recommendations = defaultdict(float)\n",
        "    similar_users100 = find_similar_users_with_compute_pearson(selectedUser,similarUser,user_item_matrix)\n",
        "    #r_a(mean target user rating)\n",
        "    availableRatingInA=[]\n",
        "    #filtering out rating in A which is the target user where rating in not \"NaN\"\n",
        "    for i in range(1,len(user_item_matrix.loc[selectedUser])):\n",
        "      if(not math.isnan(user_item_matrix.loc[selectedUser][i])):\n",
        "        availableRatingInA.append(user_item_matrix.loc[selectedUser][i])\n",
        "    meanRA=np.mean(availableRatingInA)\n",
        "\n",
        "    for movie in user_item_matrix.columns:\n",
        "        if pd.isna(user_ratings[movie]) or user_ratings[movie] == 0:\n",
        "            predicted_rating = prediction_funciton_inclass(selectedUser, movie,similar_users100,meanRA, user_item_matrix)\n",
        "            #predicted rating for the movie considered is stored in movie recommendation variable.\n",
        "            if predicted_rating>5:\n",
        "              predicted_rating=5\n",
        "            else:\n",
        "              predicted_rating\n",
        "            new_movie_recommendations[movie] = predicted_rating\n",
        "        #else:\n",
        "            #the rating of the movie which the target user already has is also being append to the movie recommendation variable.\n",
        "            #movie_recommendations[movie] = user_ratings[movie]\n",
        "    return sorted(new_movie_recommendations.items(), key=lambda x: x[1], reverse=True)[:topMovies]\n",
        "\n",
        "# Takes each member from the given group(list of similar user) and predicts top K movies fro each user.\n",
        "def predict_topMovies_for_users(users,user_item_matrix):\n",
        "    topMoviesToConsider=300\n",
        "    topSimilarUserToConsider=100\n",
        "    predictedRatings=[0]*len(users)\n",
        "    i=0\n",
        "    for user in users:\n",
        "      predictedRatings[i]=(predict_topmovies_forSingleUser(user,topMoviesToConsider,topSimilarUserToConsider,user_item_matrix))\n",
        "      i+=1\n",
        "\n",
        "    return predictedRatings\n",
        "\n"
      ],
      "metadata": {
        "id": "Hms3MXkA_LvE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Average Aggregation method\n",
        "\n",
        "def average_aggregation(users_top_common_movie_rating):\n",
        "    # Find the average of the user ratings for a movie(average rating for each movie)\n",
        "\n",
        "    avg_ratings = {}\n",
        "\n",
        "    for singleUserRecomList in users_top_common_movie_rating:\n",
        "        for movie_id, rating in singleUserRecomList:\n",
        "            if movie_id not in avg_ratings:\n",
        "                avg_ratings[movie_id] = rating\n",
        "            else:\n",
        "                avg_ratings[movie_id] = avg_ratings[movie_id]+rating\n",
        "\n",
        "    # Convert the dictionary items back to a list of tuples\n",
        "    avgResult = [(movie_id, min_rating/3) for movie_id, min_rating in avg_ratings.items()]\n",
        "\n",
        "\n",
        "    return avgResult"
      ],
      "metadata": {
        "id": "8PIowdf4lfMz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Weighted Average Aggregation method\n",
        "\n",
        "def weighted_average_aggregation(users_top_common_movie_rating,user_item_matrix,users):\n",
        "  Weighted_avg_ratings = {}\n",
        "\n",
        "  #computing weights for each user based on the number of movies they had rated. Eg: if they has rated 65 movies their weight is 0.65 if other user had rated 20 movie his weight is 0.20\n",
        "  weightOfUsers=[]\n",
        "  for user in users:\n",
        "    weightOfUsers.append(np.count_nonzero(~np.isnan(user_item_matrix.iloc[user,:]))/100)\n",
        "  i=0\n",
        "  for singleUserRecomList in users_top_common_movie_rating:\n",
        "    #print(singleUserRecomList)\n",
        "\n",
        "    weight = weightOfUsers[i]\n",
        "    #print(weight)\n",
        "    for movie_id, rating in singleUserRecomList:\n",
        "      if movie_id not in Weighted_avg_ratings:\n",
        "        Weighted_avg_ratings[movie_id] = weight*rating\n",
        "      else:\n",
        "        Weighted_avg_ratings[movie_id] = Weighted_avg_ratings[movie_id]+weight*rating\n",
        "    i+=1\n",
        "  totalWeight=sum(weightOfUsers)\n",
        "  # Convert the dictionary items back to a list of tuples\n",
        "  weightedAvgResult = [(movie_id, min_rating/totalWeight) for movie_id, min_rating in Weighted_avg_ratings.items()]\n",
        "\n",
        "  return weightedAvgResult"
      ],
      "metadata": {
        "id": "pWoSjI_rq9SX"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Least Misery Aggregation\n",
        "def least_misery_aggregation(users_top_common_movie_rating):\n",
        "    # Find the least satisfied user (min rating for each movie)\n",
        "    # Create a dictionary to store the minimum rating for each movie id\n",
        "    min_ratings = {}\n",
        "\n",
        "    # Iterate through each sublist and update the dictionary with the minimum rating for each movie id\n",
        "    for singleUserRecomList in users_top_common_movie_rating:\n",
        "        for movie_id, rating in singleUserRecomList:\n",
        "            if movie_id not in min_ratings or rating < min_ratings[movie_id]:\n",
        "                min_ratings[movie_id] = rating\n",
        "\n",
        "    # Convert the dictionary items back to a list of tuples\n",
        "    least_satisfied_user = [(movie_id, min_rating) for movie_id, min_rating in min_ratings.items()]\n",
        "\n",
        "    return least_satisfied_user"
      ],
      "metadata": {
        "id": "JTA8x4TKokK2"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating Satisfaction scores for single user:\n",
        "\n",
        "# when user satisfaction is 1, that person is completely satisfied. All the movies from their top K list are in the group recommendations top K list.\n",
        "def computeUserSatisfactions(users_top_common_movie_rating,AggregatedOutputMovieIds,topMovies):\n",
        "      #here we will sum up all the movie ratings available in the top K list for the target user\n",
        "    singleUserSatisfactionScore=[]\n",
        "    for singleUserRecom in users_top_common_movie_rating:\n",
        "      singleUserRecom=sorted(singleUserRecom, key=lambda x: x[1],reverse=True)[:topMovies]\n",
        "      #this is computed by summing up the ratings of the movies in the top K list which are common for target users top K list and also we will be summing up these moving rating value from the target user list not the rating value available in group prediction list.\n",
        "      groupSatisfactionScore=0\n",
        "      currentSingleUserSatisfactionScore=sum(x[1] for x in singleUserRecom)\n",
        "      #print(singleUserRecom)\n",
        "      #print(AggregatedOutputMovieIds)\n",
        "      for movieId, rating in singleUserRecom:\n",
        "        #print(movieId,rating)\n",
        "        if(movieId in AggregatedOutputMovieIds):\n",
        "          groupSatisfactionScore+=rating\n",
        "        #print(\"groupSatisfactionScore\")\n",
        "        #print(groupSatisfactionScore)\n",
        "        #print(\"currentSingleUserSatisfactionScore\")\n",
        "        #print(currentSingleUserSatisfactionScore)\n",
        "      singleUserSatisfactionScore.append(groupSatisfactionScore/currentSingleUserSatisfactionScore)\n",
        "    return singleUserSatisfactionScore\n"
      ],
      "metadata": {
        "id": "jmYB0tWmzDhi"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hybrid_aggregation_model(AVG_aggregatedOutput,LM_aggregatedOutput,disagreement):\n",
        "  avgAggregatedMovieListSorted=sorted(AVG_aggregatedOutput, key=lambda x: x[0], reverse=True)\n",
        "  lmAggregatedMovieListSorted=sorted(LM_aggregatedOutput, key=lambda x: x[0], reverse=True)\n",
        "  computedMovieList=[]\n",
        "    #Formula to prepare an hybrid model\n",
        "  for avgMovieItem,LMMovieItem in zip(avgAggregatedMovieListSorted,lmAggregatedMovieListSorted):\n",
        "    avgMovieId,avgMovieRating = avgMovieItem\n",
        "    lmMovieId,lmMovieRating = LMMovieItem\n",
        "    #check whether the considered movie IDs are same from both list to avoid miscomputaion\n",
        "    if(avgMovieId==lmMovieId):\n",
        "      computedMovieList.append((avgMovieId,((1-disagreement)*avgMovieRating)+((disagreement)*lmMovieRating)))\n",
        "  return sorted(computedMovieList, key=lambda x: x[1], reverse=True)\n"
      ],
      "metadata": {
        "id": "0wQFST_GRqhL"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_Disagreement(userSatisfactionScores):\n",
        "  #Using Coefficient of Variation (CV) approach\n",
        "  cv = (np.std(userSatisfactionScores) / np.mean(userSatisfactionScores))\n",
        "  return cv\n"
      ],
      "metadata": {
        "id": "SxA-WQ95-j-M"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predictTopCommonMoviesAndComputeAggregatedList(users,user_item_matrix):\n",
        "  predictedRatings=predict_topMovies_for_users(users,user_item_matrix)\n",
        "  first_elements_1 = {t[0] for t in predictedRatings[0]}\n",
        "  first_elements_2 = {t[0] for t in predictedRatings[1]}\n",
        "  first_elements_3 = {t[0] for t in predictedRatings[2]}\n",
        "  common_movies= first_elements_1.intersection(first_elements_2, first_elements_3)\n",
        "  filtered_list1 = sorted([t for t in predictedRatings[0] if t[0] in common_movies], key=lambda x: x[0])\n",
        "  filtered_list2 = sorted([t for t in predictedRatings[1] if t[0] in common_movies], key=lambda x: x[0])\n",
        "  filtered_list3 = sorted([t for t in predictedRatings[2] if t[0] in common_movies], key=lambda x: x[0])\n",
        "  #print(\"User \",users[0],\"common movie rating in top 200 movies\")\n",
        "  #print(filtered_list1)\n",
        "  #print(\"User \",users[1],\"common movie rating in top 200 movies\")\n",
        "  #print(filtered_list2)\n",
        "  #print(\"User \",users[2],\"common movie rating in top 200 movies\")\n",
        "  #print(filtered_list3)\n",
        "  users_top_common_movie_rating=[filtered_list1,filtered_list2,filtered_list3]\n",
        "\n",
        "  #Aggregating with Average aggregation\n",
        "  #AVG_aggregatedOutput_unsorted=average_aggregation(users_top_common_movie_rating)\n",
        "\n",
        "  #Aggregating with Weighted Average aggregation\n",
        "  WEIGHTED_AVG_aggregatedOutput_unsorted=weighted_average_aggregation(users_top_common_movie_rating,user_item_matrix,users)\n",
        "\n",
        "  #Aggregating using least misery\n",
        "  LM_aggregatedOutput_unsorted=least_misery_aggregation(users_top_common_movie_rating)\n",
        "\n",
        "  #return AVG_aggregatedOutput_unsorted,LM_aggregatedOutput_unsorted,users_top_common_movie_rating\n",
        "  return WEIGHTED_AVG_aggregatedOutput_unsorted,LM_aggregatedOutput_unsorted,users_top_common_movie_rating"
      ],
      "metadata": {
        "id": "E2-D4l4d5WiD"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chunkingDataset(num_chunks):\n",
        "\n",
        "  totalUsers=len(user_item_matrix)\n",
        "  user_chunk_size = totalUsers // num_chunks\n",
        "  user_chunks = [user_chunk_size] * num_chunks\n",
        "  countedUserChunk=sum(user_chunks)\n",
        "  usersPerChunk = list(np.cumsum(user_chunks))\n",
        "\n",
        "  #checking for missing user due to uneven splitting\n",
        "  if(countedUserChunk!=totalUsers):\n",
        "    usersPerChunk[num_chunks-1]=usersPerChunk[num_chunks-1]+(totalUsers-countedUserChunk)\n",
        "\n",
        "  totalMovies=user_item_matrix.shape[1]\n",
        "  movie_chunk_size = totalMovies // num_chunks\n",
        "  movie_chunks = [movie_chunk_size] * num_chunks\n",
        "  countedMovieChunk=sum(movie_chunks)\n",
        "  moviesPerChunk = list(np.cumsum(movie_chunks))\n",
        "\n",
        "  #checking for missing movie due to uneven splitting\n",
        "  if(countedMovieChunk!=totalMovies):\n",
        "    moviesPerChunk[num_chunks-1]=moviesPerChunk[num_chunks-1]+(totalMovies-countedMovieChunk)\n",
        "\n",
        "  print(\"Chunking the Input Dataset\\n\")\n",
        "  for i in range(len(usersPerChunk)):\n",
        "    print(\"Dataset Chunk\",i+1,\"which has\",usersPerChunk[i],\"users and\",moviesPerChunk[i],\"movies.\")\n",
        "\n",
        "  print(\"\\n\")\n",
        "  chunks = []\n",
        "\n",
        "  # Loop through each chunk and create the submatrix\n",
        "  for i in range(num_chunks):\n",
        "      chunk = user_item_matrix.iloc[0:usersPerChunk[i], 0:moviesPerChunk[i]]\n",
        "      chunks.append(chunk)\n",
        "  return chunks\n"
      ],
      "metadata": {
        "id": "ACvH6uR3gI3X"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sequence of group recommendation\n",
        "\n",
        "def sequenceGroupRecommendation(iteration,users,topMovies):\n",
        "  allGroupRecommendation=[]\n",
        "  allRecommendedMovieID=[]\n",
        "  groupRecommendationForCurrentIteration=[]\n",
        "  topKMovieIdsForCurrentIteration=[]\n",
        "  groupSatisfactions=[]\n",
        "  allUserSatisfactionsForCurrentIteration=[]\n",
        "  allGroupDisagreements=[]\n",
        "  allMovieIds=[]\n",
        "\n",
        "  #chunking Data\n",
        "  chunks = chunkingDataset(iteration)\n",
        "\n",
        "  for iter in range(iteration+1):\n",
        "    if(iter==0):\n",
        "      num_users, num_movies = chunks[iter].shape\n",
        "      print(\"Predicting Recommendations for Sequence 1 for the given group of users\",users,\"using the splitted chunk 1 of the dataset which has\",num_users,\"users and\",num_movies,\"movies rated by them.\\n\")\n",
        "      Weighted_aggregatedOutput_unsorted,LM_aggregatedOutput_unsorted,users_top_common_movie_rating=predictTopCommonMoviesAndComputeAggregatedList(users,chunks[iter])\n",
        "      WeightedAggregatedMovieListSorted=sorted(Weighted_aggregatedOutput_unsorted, key=lambda x: x[1], reverse=True)\n",
        "      lmAggregatedMovieListSorted=sorted(LM_aggregatedOutput_unsorted, key=lambda x: x[1], reverse=True)\n",
        "      for avgMovie in WeightedAggregatedMovieListSorted[:topMovies]:\n",
        "        groupRecommendationForCurrentIteration.append(avgMovie)\n",
        "        allMovieIds.append(avgMovie[0])\n",
        "        topKMovieIdsForCurrentIteration.append(avgMovie[0])\n",
        "      #print(allMovieIds)\n",
        "    else:\n",
        "      userSatisfaction=computeUserSatisfactions(users_top_common_movie_rating,topKMovieIdsForCurrentIteration,topMovies)\n",
        "      print(\"\\n\\nUser satisfaction scores from iteration sequence\",iter,\"is\",userSatisfaction,\"which is computed using round\",iter,\"recommended list\")\n",
        "      groupSatisfactions.append(np.mean(userSatisfaction))\n",
        "      groupDisagreementForCurrentIteration=compute_Disagreement(userSatisfaction)\n",
        "      print(\"User disagreement score from iteration sequence\",iter,\"is\",groupDisagreementForCurrentIteration,\"which is computed using round\",iter,\"recommended list\")\n",
        "      allGroupDisagreements.append(groupDisagreementForCurrentIteration)\n",
        "      if (iter != iteration):\n",
        "        num_users, num_movies = chunks[iter].shape\n",
        "        print(\"\\nPredicting Recommendations for Sequence\",iter+1,\" for the given group of users\",users,\"using the splitted chunk\",iter+1,\"of the dataset which has\",num_users,\"users and\",num_movies,\"movies rated by them.\\n\")\n",
        "        Weighted_aggregatedOutput_unsorted,LM_aggregatedOutput_unsorted,users_top_common_movie_rating=predictTopCommonMoviesAndComputeAggregatedList(users,chunks[iter])\n",
        "        newmovieList=hybrid_aggregation_model(Weighted_aggregatedOutput_unsorted,LM_aggregatedOutput_unsorted,groupDisagreementForCurrentIteration)\n",
        "        notYetRecommendedNewMovieList=[(t,p) for t,p in newmovieList if t not in allMovieIds]\n",
        "        groupRecommendationForCurrentIteration=notYetRecommendedNewMovieList[0:topMovies]\n",
        "        topKMovieIdsForCurrentIteration=[t for t,p in groupRecommendationForCurrentIteration]\n",
        "        allMovieIds.append([t for t,p in groupRecommendationForCurrentIteration])\n",
        "        allMovieIds = [item for sublist in allMovieIds for item in (sublist if isinstance(sublist, list) else [sublist])]\n",
        "        #print(allMovieIds)\n",
        "      else:\n",
        "        continue\n",
        "    print(\"\\n\\nTop\",topMovies,\"movies Recommended for the group which has users\",users,\"for the sequence itertion\",iter + 1,\"are\")\n",
        "    for movie, rating in groupRecommendationForCurrentIteration:\n",
        "      print(f\"Movie Name: {movies.loc[movie][1]}, Movie ID: {movie}, Predicted Rating: {rating:.0f}, Release Date: {movies.loc[movie][2]}\")\n",
        "  print(\"\\nOverall Group Satisfaction after\",iteration,\"itertion of recommending top\",topMovies,\"movies is\",np.mean(groupSatisfactions))\n",
        "  print(\"\\nThe Overall progression of group satisfaction for\",iteration,\"iterations are\",groupSatisfactions)\n",
        "  print(\"\\nThe Overall progression of group disagreement for\",iteration,\"iterations are\",allGroupDisagreements)\n"
      ],
      "metadata": {
        "id": "tYE65Xo_Gb9Q"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#testing\n",
        "#different users can be selected but the current implementation only allows group of 3 users(fixed).\n",
        "users=[145, 146, 148]\n",
        "#users=[61,  63,  69]\n",
        "#required sequence of recommendations can be mentioned here eg:3 iterations\n",
        "sequenceIteration=3\n",
        "#required top k results of movies can be mentioned here Eg:10 (will result top 10 recommended movies for the group at each sequence of recommendation).\n",
        "topMovies=10\n",
        "#compute sequential recommendation\n",
        "sequenceGroupRecommendation(sequenceIteration,users,topMovies)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2pQ1bBxI_Ag",
        "outputId": "082e5fad-3159-42cc-8a91-0dd1e8037227"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunking the Input Dataset\n",
            "\n",
            "Dataset Chunk 1 which has 314 users and 560 movies.\n",
            "Dataset Chunk 2 which has 628 users and 1120 movies.\n",
            "Dataset Chunk 3 which has 943 users and 1682 movies.\n",
            "\n",
            "\n",
            "Predicting Recommendations for Sequence 1 for the given group of users [145, 146, 148] using the splitted chunk 1 of the dataset which has 314 users and 560 movies rated by them.\n",
            "\n",
            "predicting for user 145\n",
            "predicting for user 146\n",
            "predicting for user 148\n",
            "\n",
            "\n",
            "Top 10 movies Recommended for the group which has users [145, 146, 148] for the sequence itertion 1 are\n",
            "Movie Name: Batman & Robin (1997), Movie ID: 253, Predicted Rating: 5, Release Date: 20-Jun-1997\n",
            "Movie Name: Delicatessen (1991), Movie ID: 170, Predicted Rating: 5, Release Date: 01-Jan-1991\n",
            "Movie Name: Third Man, The (1949), Movie ID: 512, Predicted Rating: 5, Release Date: 01-Jan-1949\n",
            "Movie Name: Lost World: Jurassic Park, The (1997), Movie ID: 251, Predicted Rating: 5, Release Date: 23-May-1997\n",
            "Movie Name: Exotica (1994), Movie ID: 45, Predicted Rating: 5, Release Date: 01-Jan-1994\n",
            "Movie Name: Maltese Falcon, The (1941), Movie ID: 483, Predicted Rating: 4, Release Date: 01-Jan-1941\n",
            "Movie Name: Ben-Hur (1959), Movie ID: 525, Predicted Rating: 4, Release Date: 01-Jan-1959\n",
            "Movie Name: Manhattan (1979), Movie ID: 516, Predicted Rating: 4, Release Date: 01-Jan-1979\n",
            "Movie Name: Annie Hall (1977), Movie ID: 513, Predicted Rating: 4, Release Date: 01-Jan-1977\n",
            "Movie Name: Manon of the Spring (Manon des sources) (1986), Movie ID: 165, Predicted Rating: 4, Release Date: 01-Jan-1986\n",
            "\n",
            "\n",
            "User satisfaction scores from iteration sequence 1 is [0.5043157187740493, 0.5036350679624577, 0.6002083268553412] which is computed using round 1 recommended list\n",
            "User disagreement score from iteration sequence 1 is 0.08462873582001458 which is computed using round 1 recommended list\n",
            "\n",
            "Predicting Recommendations for Sequence 2  for the given group of users [145, 146, 148] using the splitted chunk 2 of the dataset which has 628 users and 1120 movies rated by them.\n",
            "\n",
            "predicting for user 145\n",
            "predicting for user 146\n",
            "predicting for user 148\n",
            "\n",
            "\n",
            "Top 10 movies Recommended for the group which has users [145, 146, 148] for the sequence itertion 2 are\n",
            "Movie Name: Mother (1996), Movie ID: 320, Predicted Rating: 5, Release Date: 25-Dec-1996\n",
            "Movie Name: Fast, Cheap & Out of Control (1997), Movie ID: 1021, Predicted Rating: 5, Release Date: 01-Jan-1997\n",
            "Movie Name: Little Princess, A (1995), Movie ID: 1062, Predicted Rating: 4, Release Date: 01-Jan-1995\n",
            "Movie Name: Bad Taste (1987), Movie ID: 853, Predicted Rating: 4, Release Date: 01-Jan-1987\n",
            "Movie Name: English Patient, The (1996), Movie ID: 285, Predicted Rating: 4, Release Date: 15-Nov-1996\n",
            "Movie Name: Notorious (1946), Movie ID: 488, Predicted Rating: 4, Release Date: 01-Jan-1946\n",
            "Movie Name: Ruby in Paradise (1993), Movie ID: 961, Predicted Rating: 4, Release Date: 01-Jan-1993\n",
            "Movie Name: My Fellow Americans (1996), Movie ID: 863, Predicted Rating: 4, Release Date: 20-Dec-1996\n",
            "Movie Name: My Fair Lady (1964), Movie ID: 484, Predicted Rating: 4, Release Date: 01-Jan-1964\n",
            "Movie Name: Ninotchka (1939), Movie ID: 835, Predicted Rating: 4, Release Date: 01-Jan-1939\n",
            "\n",
            "\n",
            "User satisfaction scores from iteration sequence 2 is [0.3096050987348396, 0.5044093146372453, 0.40566815034946213] which is computed using round 2 recommended list\n",
            "User disagreement score from iteration sequence 2 is 0.19561891491957895 which is computed using round 2 recommended list\n",
            "\n",
            "Predicting Recommendations for Sequence 3  for the given group of users [145, 146, 148] using the splitted chunk 3 of the dataset which has 943 users and 1682 movies rated by them.\n",
            "\n",
            "predicting for user 145\n",
            "predicting for user 146\n",
            "predicting for user 148\n",
            "\n",
            "\n",
            "Top 10 movies Recommended for the group which has users [145, 146, 148] for the sequence itertion 3 are\n",
            "Movie Name: To Be or Not to Be (1942), Movie ID: 1203, Predicted Rating: 4, Release Date: 01-Jan-1942\n",
            "Movie Name: Everyone Says I Love You (1996), Movie ID: 318, Predicted Rating: 4, Release Date: 06-Dec-1996\n",
            "Movie Name: Blue Angel, The (Blaue Engel, Der) (1930), Movie ID: 616, Predicted Rating: 4, Release Date: 01-Jan-1930\n",
            "Movie Name: Vanya on 42nd Street (1994), Movie ID: 463, Predicted Rating: 4, Release Date: 01-Jan-1994\n",
            "Movie Name: Night of the Living Dead (1968), Movie ID: 615, Predicted Rating: 4, Release Date: 01-Jan-1968\n",
            "Movie Name: Dead Man (1995), Movie ID: 921, Predicted Rating: 4, Release Date: 10-May-1996\n",
            "Movie Name: Meet Me in St. Louis (1944), Movie ID: 604, Predicted Rating: 4, Release Date: 01-Jan-1944\n",
            "Movie Name: Wings of Desire (1987), Movie ID: 511, Predicted Rating: 4, Release Date: 01-Jan-1987\n",
            "Movie Name: Apartment, The (1960), Movie ID: 480, Predicted Rating: 4, Release Date: 01-Jan-1960\n",
            "Movie Name: Day the Earth Stood Still, The (1951), Movie ID: 428, Predicted Rating: 4, Release Date: 01-Jan-1951\n",
            "\n",
            "\n",
            "User satisfaction scores from iteration sequence 3 is [0.5967157083739638, 0.30230109716881326, 0.4036721447688073] which is computed using round 3 recommended list\n",
            "User disagreement score from iteration sequence 3 is 0.2812360005787568 which is computed using round 3 recommended list\n",
            "\n",
            "Overall Group Satisfaction after 3 itertion of recommending top 10 movies is 0.4589478475138866\n",
            "\n",
            "The Overall progression of group satisfaction for 3 iterations are [0.5360530378639495, 0.406560854573849, 0.43422965010386144]\n",
            "\n",
            "The Overall progression of group disagreement for 3 iterations are [0.08462873582001458, 0.19561891491957895, 0.2812360005787568]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
